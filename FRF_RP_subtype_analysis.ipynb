{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import xlrd\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "from pandas import DataFrame\n",
    "import scipy as sc\n",
    "from scipy import io\n",
    "from scipy.stats import pearsonr\n",
    "from os.path import join, exists, dirname\n",
    "from glob import glob\n",
    "from brainspace import gradient\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start characterize subytpe using Funtaional Random Forest result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_excel(join(path_data, 'abide_func_fn_abideII_sorted.xlsx'), sheet_name='Sheet1', skiprows=0)\n",
    "\n",
    "sub_list = demo['ID']\n",
    "label2 = demo['Group']\n",
    "label = demo['DX_GROUP']\n",
    "site_id = demo['Site']\n",
    "site_label = demo['SITE_Label']\n",
    "Age = demo['Age']\n",
    "FD = demo['MeanFD_Jenkinson'] # = func_mean_fd\n",
    "IQ = demo['FIQ']\n",
    "sex = demo['Sex']\n",
    "\n",
    "ASD_index = np.where(label == 1)[0]                \n",
    "TD_index = np.where(label == 2)[0]\n",
    "Total_index = np.concatenate((ASD_index,TD_index)) \n",
    "sorted_idx = np.concatenate((ASD_index,TD_index), axis = 0)\n",
    "\n",
    "site_label_sorted = np.array(site_label)[sorted_idx]\n",
    "\n",
    "male_idx = np.where(sex=='M')[0]\n",
    "label_male = np.array(label[male_idx])\n",
    "ASD_male_idx = np.array(list(set(np.where(label == 1)[0]) & set(male_index)))\n",
    "TD_male_idx = np.array(list(set(np.where(label == 2)[0]) & set(male_index)))\n",
    "sorted_male_idx = np.concatenate((ASD_male_idx, TD_male_idx), axis=0)\n",
    "\n",
    "whole2male_idx_ABD2 = np.array([np.where(sorted_idx==sorted_male_idx[i])[0][0] for i in range(len(sorted_male_idx))])\n",
    "\n",
    "print('Total : ', len(Total_index), len(sorted_male_idx))\n",
    "print('ASD : ', len(ASD_index), len(ASD_male_idx))\n",
    "print('TD : ', len(TD_index), len(TD_male_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reg out mat\n",
    "\n",
    "subj_num = 103\n",
    "grad_num = 1\n",
    "Thresh = 'top50' # top50\n",
    "valid = '_Valid' # '_Valid' ''\n",
    "\n",
    "main_result = False\n",
    "\n",
    "if main_result:\n",
    "    regout_mat = sc.io.loadmat(join(path_data,f'Gradient{grad_num}_Surf_pearson_sorted_regout_gender_Mean_har_n{subj_num}_{Thresh}_ABD2.mat'))\n",
    "\n",
    "    PCs_sorted_reg_out = regout_mat['total_group_data'][:,:360]\n",
    "\n",
    "    grp_ASD_PCs_reg_out = PCs_sorted_reg_out[:len(ASD_index),:]\n",
    "    grp_TD_PCs_reg_out = PCs_sorted_reg_out[len(ASD_index):,:]\n",
    "\n",
    "    # Load FRF subtype result\n",
    "\n",
    "    folder = f'Gradient{grad_num}_pearson_MeanHar_n{subj_num}_{Thresh}_1000iter_1perm_rtoz_ABD_2_FeaSel{valid}_output'\n",
    "    FRF_outbputs_DMN_pcs = sc.io.loadmat(join(path_mat,f'{folder}/subgroup_community_assignments.mat'))\n",
    "else:\n",
    "    Topk='Top50'\n",
    "    regout_mat = sc.io.loadmat(join(path_data,f'Gradient{grad_num}_Surf_pearson_sorted_regout_gender_Mean_har_n{subj_num}_{Thresh}_ABD2.mat'))\n",
    "    PCs_sorted_reg_out = regout_mat['total_group_data'][whole2male_idx_ABD2,:360] # whole2male_idx_ABD2\n",
    "    label = regout_mat['total_group_data'][whole2male_idx_ABD2,360] # whole2male_idx_ABD2\n",
    "    grp_ASD_PCs_reg_out = PCs_sorted_reg_out[np.where(label==1)[0], :] # np.where(label==1)[0] \n",
    "    grp_TD_PCs_reg_out = PCs_sorted_reg_out[np.where(label==2)[0], :] # np.where(label==2)[0] \n",
    "    \n",
    "    ASD_label_idx = np.where(label==1)[0]\n",
    "    TD_label_idx = np.where(label==2)[0]\n",
    "\n",
    "    # Load FRF subtype result\n",
    "    folder = f'Gradient{grad_num}_pearson_MeanHar_{Thresh}_100iter_1perm_rtoz_FeaSel_split06_valid_male_ABD2_output'\n",
    "    FRF_outbputs_DMN_pcs = sc.io.loadmat(join(path_mat,'review','Top50_main',f'{folder}/subgroup_community_assignments.mat'))    \n",
    "\n",
    "# subgroup_order\n",
    "subgroup_order = []\n",
    "for i in range(len(male_index)):\n",
    "    subgroup_order.append(FRF_outbputs_DMN_pcs['subgroup_community_assignments'][i][0][0])\n",
    "    \n",
    "# subgroup_order\n",
    "ASD1 = np.where(np.array(subgroup_order)=='G1_1')[0].shape[0]\n",
    "ASD2 = np.where(np.array(subgroup_order)=='G1_2')[0].shape[0]\n",
    "ASD3 = np.where(np.array(subgroup_order)=='G1_3')[0].shape[0]\n",
    "ASD4 = np.where(np.array(subgroup_order)=='G1_4')[0].shape[0]\n",
    "\n",
    "TD1 = np.where(np.array(subgroup_order)=='G2_1')[0].shape[0]\n",
    "TD2 = np.where(np.array(subgroup_order)=='G2_2')[0].shape[0]\n",
    "TD3 = np.where(np.array(subgroup_order)=='G2_3')[0].shape[0]\n",
    "TD4 = np.where(np.array(subgroup_order)=='G2_4')[0].shape[0]\n",
    "TD5 = np.where(np.array(subgroup_order)=='G2_5')[0].shape[0]\n",
    "\n",
    "# Assign subtype idx\n",
    "ASD_DMN_pc_sub1_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][0][0].reshape(-1,),dtype='int64')[:ASD1]-1\n",
    "ASD_DMN_pc_sub2_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][0][0].reshape(-1,),dtype='int64')[ASD1 : ASD1+ASD2]-1\n",
    "ASD_DMN_pc_sub3_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][0][0].reshape(-1,),dtype='int64')[ASD1+ASD2:ASD1+ASD2+ASD3]-1\n",
    "ASD_DMN_pc_sub4_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][0][0].reshape(-1,),dtype='int64')[ASD1+ASD2+ASD3:]-1\n",
    "\n",
    "\n",
    "TD_DMN_pc_sub1_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][1][0].reshape(-1,),dtype='int64')[:TD1]-1\n",
    "TD_DMN_pc_sub2_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][1][0].reshape(-1,),dtype='int64')[TD1 : TD1+TD2]-1   \n",
    "TD_DMN_pc_sub3_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][1][0].reshape(-1,),dtype='int64')[TD1+TD2 :TD1+TD2+TD3]-1  \n",
    "TD_DMN_pc_sub4_idx = np.array(FRF_outbputs_DMN_pcs['subgroup_sorting_orders'][1][0].reshape(-1,),dtype='int64')[TD1+TD2+TD3 :]-1  \n",
    "\n",
    "\n",
    "ASD_DMN_pc_sub1 = grp_ASD_PCs_reg_out[ASD_DMN_pc_sub1_idx,:]\n",
    "ASD_DMN_pc_sub2 = grp_ASD_PCs_reg_out[ASD_DMN_pc_sub2_idx,:]\n",
    "ASD_DMN_pc_sub3 = grp_ASD_PCs_reg_out[ASD_DMN_pc_sub3_idx,:]\n",
    "ASD_DMN_pc_sub4 = grp_ASD_PCs_reg_out[ASD_DMN_pc_sub4_idx,:]\n",
    "\n",
    "\n",
    "TD_DMN_pc_sub1 = grp_TD_PCs_reg_out[TD_DMN_pc_sub1_idx,:]\n",
    "TD_DMN_pc_sub2 = grp_TD_PCs_reg_out[TD_DMN_pc_sub2_idx,:]\n",
    "TD_DMN_pc_sub3 = grp_TD_PCs_reg_out[TD_DMN_pc_sub3_idx,:]\n",
    "TD_DMN_pc_sub4 = grp_TD_PCs_reg_out[TD_DMN_pc_sub4_idx,:]\n",
    "\n",
    "\n",
    "\n",
    "print(ASD_DMN_pc_sub1.shape)\n",
    "print(ASD_DMN_pc_sub2.shape)\n",
    "print(ASD_DMN_pc_sub3.shape)\n",
    "print(ASD_DMN_pc_sub4.shape)\n",
    "\n",
    "\n",
    "print(' ')\n",
    "print(TD_DMN_pc_sub1.shape)\n",
    "print(TD_DMN_pc_sub2.shape)\n",
    "print(TD_DMN_pc_sub3.shape)\n",
    "print(TD_DMN_pc_sub4.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADOS_Score assignment\n",
    "label = np.array(demo['DX_GROUP'])\n",
    "\n",
    "ADOS_Total = np.nan_to_num(np.array(demo['ADOS_G_TOTAL']), nan = -1e-16) # -9999 -> -1, nan -> -2\n",
    "ADOS_Total = np.where(ADOS_Total == -999, -1e-16, ADOS_Total)\n",
    "ADOS_Total\n",
    "ADOS_Total_sorted = ADOS_Total[sorted_idx]\n",
    "\n",
    "ADOS_comm = np.nan_to_num(np.array(demo['ADOS_G_COMM']), nan = -1e-16)\n",
    "ADOS_comm = np.where(ADOS_comm == -999, -1e-16, ADOS_comm)\n",
    "ADOS_comm_sorted = ADOS_comm[sorted_idx]\n",
    "\n",
    "ADOS_social =  np.nan_to_num(np.array(demo['ADOS_G_SOCIAL']), nan = -1e-16)\n",
    "ADOS_social = np.where(ADOS_social == -999, -1e-16, ADOS_social)\n",
    "ADOS_social_sorted = ADOS_social[sorted_idx]\n",
    "\n",
    "ADOS_behav =  np.nan_to_num(np.array(demo['ADOS_G_STEREO_BEHAV']), nan = -1e-16)\n",
    "ADOS_behav = np.where(ADOS_behav == -999, -1e-16, ADOS_behav)\n",
    "ADOS_behav_sorted = ADOS_behav[sorted_idx]\n",
    "\n",
    "age_sorted = np.array(Age)[sorted_idx]\n",
    "iq_sorted = np.array(IQ)[sorted_idx]\n",
    "sex_sorted = np.array(sex)[sorted_idx]\n",
    "\n",
    "x = ADOS_Total_sorted[whole2male_idx_ABD2]\n",
    "y = ADOS_comm_sorted[whole2male_idx_ABD2]\n",
    "z = ADOS_social_sorted[whole2male_idx_ABD2]\n",
    "t = ADOS_behav_sorted[whole2male_idx_ABD2]\n",
    "u = age_sorted[whole2male_idx_ABD2]\n",
    "v = iq_sorted[whole2male_idx_ABD2]\n",
    "\n",
    "idx1 = ASD_DMN_pc_sub1_idx\n",
    "idx2 = ASD_DMN_pc_sub2_idx\n",
    "idx3 = ASD_DMN_pc_sub3_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "ADOS_Total = []\n",
    "ADOS_Comm = []\n",
    "ADOS_Social = []\n",
    "ADOS_Behav = []\n",
    "age = []\n",
    "iq = []\n",
    "\n",
    "idx_list1 = [idx1, idx1, idx2] # idx3, idx3, idx1\n",
    "idx_list2 = [idx2, idx3, idx3] # idx1, idx2, idx2\n",
    "\n",
    "for i in range(3):\n",
    "    a = idx_list1[i] # idx1 idx1 idx2\n",
    "    b = idx_list2[i] # idx2 idx3 idx3\n",
    "\n",
    "    [s_0,p_0] = sc.stats.ttest_ind(x[a][x[a]>=0], x[b][x[b]>=0], equal_var=False, axis=0)\n",
    "    [s_1,p_1] = sc.stats.ttest_ind(y[a][y[a]>=0], y[b][y[b]>=0], equal_var=False, axis=0) \n",
    "    [s_2,p_2] = sc.stats.ttest_ind(z[a][z[a]>=0], z[b][z[b]>=0], equal_var=False, axis=0) \n",
    "    [s_3,p_3] = sc.stats.ttest_ind(t[a][t[a]>=0], t[b][t[b]>=0], equal_var=False, axis=0)\n",
    "    [s_4,p_4] = sc.stats.ttest_ind(u[a][u[a]>=0], u[b][u[b]>=0], equal_var=False, axis=0)\n",
    "    [s_5,p_5] = sc.stats.ttest_ind(v[a][v[a]>=0], v[b][v[b]>=0], equal_var=False, axis=0)\n",
    "\n",
    "    p_0_fdr = sm.stats.multitest.multipletests(p_0,alpha=0.05,method='fdr_bh')\n",
    "    p_1_fdr = sm.stats.multitest.multipletests(p_1,alpha=0.05,method='fdr_bh')\n",
    "    p_2_fdr = sm.stats.multitest.multipletests(p_2,alpha=0.05,method='fdr_bh')\n",
    "    p_3_fdr = sm.stats.multitest.multipletests(p_3,alpha=0.05,method='fdr_bh')\n",
    "    p_4_fdr = sm.stats.multitest.multipletests(p_4,alpha=0.05,method='fdr_bh')\n",
    "    p_5_fdr = sm.stats.multitest.multipletests(p_5,alpha=0.05,method='fdr_bh')\n",
    "\n",
    "    ADOS_Total.append(p_0_fdr[1][0])\n",
    "    ADOS_Comm.append(p_1_fdr[1][0])\n",
    "    ADOS_Social.append(p_2_fdr[1][0])\n",
    "    ADOS_Behav.append(p_3_fdr[1][0])\n",
    "    age.append(p_4_fdr[1][0])\n",
    "    iq.append(p_5_fdr[1][0])\n",
    "\n",
    "result = {'ADOS_Total' : [np.round(i,4) for i in ADOS_Total], \n",
    "          'ADOS_Comm' : [np.round(i,4) for i in ADOS_Comm], \n",
    "          'ADOS_Social' : [np.round(i,4) for i in ADOS_Social],\n",
    "          'ADOS_Behav' : [np.round(i,4) for i in ADOS_Behav],\n",
    "          'Age' : [np.round(i,4) for i in age],\n",
    "          'IQ' : [np.round(i,4) for i in iq]}\n",
    "                   \n",
    "[f_age,p_age] = sc.stats.f_oneway(np.array(u)[idx1], np.array(u)[idx2], np.array(u)[idx3])\n",
    "[f_iq,p_iq] = sc.stats.f_oneway(np.array(v)[idx1][np.array(v)[idx1]>=0], np.array(v)[idx2], np.array(v)[idx3])\n",
    "    \n",
    "for key, val in result.items():\n",
    "    print(f'{key}    :    {val}')    \n",
    "    \n",
    "print(f'Age F : {np.round(f_age,3)}, p : {np.round(p_age,3)}')\n",
    "print(f'IQ F : {np.round(f_iq,3)}, p : {np.round(p_iq,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "FRF_subtype_label = np.zeros(len(ASD_label_idx))\n",
    "FRF_subtype_label[:] = np.nan\n",
    "FRF_subtype_label[idx1] =1 # 2\n",
    "FRF_subtype_label[idx2] =2 # 3\n",
    "FRF_subtype_label[idx3] =3 # 1\n",
    "\n",
    "FRF_subtype_label\n",
    "\n",
    "# y = ADOS_social_sorted # ADOS_Total_sorted ADOS_comm_sorted ADOS_social_sorted ADOS_behav_sorted\n",
    "\n",
    "score_name = ['ADOS Total','ADOS Communication','ADOS Social','ADOS Behavior', 'Age', 'IQ']\n",
    "\n",
    "for i, score in enumerate([ADOS_Total_sorted, ADOS_comm_sorted, ADOS_social_sorted, ADOS_behav_sorted, age_sorted, iq_sorted]):\n",
    "\n",
    "    df = DataFrame([score[:len(ASD_label_idx)][score[:len(ASD_label_idx)]>=0], FRF_subtype_label[[score[:len(ASD_label_idx)]>=0]]]) \n",
    "    df = df.T\n",
    "    df.columns = [score_name[i],'ASD Subtype']\n",
    "\n",
    "    plt.figure(figsize = (7,7))\n",
    "    sns.set(style = 'whitegrid', font_scale=2.5)\n",
    "    sns.boxplot(x = 'ASD Subtype' , y = df.columns[0], data = df, palette = 'gist_yarg', width=0.5)\n",
    "    sns.swarmplot(x = 'ASD Subtype' , y = df.columns[0], data = df, color = 'k', size = 4)\n",
    "    plt.xticks([0,1,2],['ASD 1','ASD 2', 'ASD 3'], fontsize=40)\n",
    "    plt.xlabel('Subtype', fontsize=40)\n",
    "    plt.ylabel(score_name[i], fontsize=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADOS Calibration score\n",
    "\n",
    "demo_cali = pd.read_excel(join(path_data, 'abide_abideII_calibration.xlsx'), sheet_name='n=103', skiprows=0)\n",
    "\n",
    "FileID_cali = demo_cali['ID']\n",
    "ADOS_Total_cali = demo_cali['ADOS_T_CSS']\n",
    "\n",
    "score = []\n",
    "for i in sub_list:\n",
    "    score.append(ADOS_Total_cali[np.where(FileID_cali == i)[0][0]])\n",
    "    \n",
    "score = np.array(score)\n",
    "\n",
    "y = score[ASD_index]\n",
    "\n",
    "df = DataFrame([y[:len(ASD_label_idx)][y[:len(ASD_label_idx)]>0], FRF_subtype_label[[y[:len(ASD_label_idx)]>0]]]) # cluster_labels[ADOS_Total_idx_sorted] SRS_exist_idx_sorted\n",
    "df = df.T\n",
    "df.columns = ['ADOS Total Calibration','ASD Subtype']\n",
    "\n",
    "plt.figure(1,(7,7))\n",
    "sns.set(style = 'whitegrid', font_scale=2.5)\n",
    "sns.boxplot(x = 'ASD Subtype' , y = df.columns[0], data = df, palette = 'gist_yarg', width=0.5)\n",
    "sns.swarmplot(x = 'ASD Subtype' , y = df.columns[0], data = df, color = 'k', size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ABD2 symptom severity score\n",
    "\n",
    "ABD2_Score = DataFrame([ADOS_Total_sorted[:len(ASD_label_idx)], ADOS_comm_sorted[:len(ASD_label_idx)], ADOS_social_sorted[:len(ASD_label_idx)], ADOS_behav_sorted[:len(ASD_label_idx)], FRF_subtype_label[:len(ASD_label_idx)]]).T\n",
    "ABD2_Score.columns = ['ADOS Total','ADOS Communication','ADOS Social','ADOS Behavior', 'ASD Subtype']\n",
    "ABD2_Score\n",
    "# ABD2_Score.to_excel(join(path_data,'ABD2_Score_male_revision.xlsx'), sheet_name = 'Sheet1', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare symptom severity between discovery and replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABD1_Score = pd.read_excel(join(path_data, 'ABD1_Score_revision.xlsx'), sheet_name='Sheet1', skiprows=0)\n",
    "ABD2_Score = pd.read_excel(join(path_data, 'ABD2_Score_male_revision.xlsx'), sheet_name='Sheet1', skiprows=0)\n",
    "\n",
    "ABD1_Score['Dataset'] = 'Discovery'\n",
    "ABD2_Score['Dataset'] = 'Replication'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_name in ['ADOS Total','ADOS Communication','ADOS Social','ADOS Behavior', 'SRS']:\n",
    "    \n",
    "    if score_name != 'SRS':\n",
    "        print(f'@@ {score_name} @@')\n",
    "\n",
    "        df_ABD1 = DataFrame([ABD1_Score[score_name], ABD1_Score['ASD Subtype'], ABD1_Score['Dataset']]).T\n",
    "        df_ABD2 = DataFrame([ABD2_Score[score_name], ABD2_Score['ASD Subtype'], ABD2_Score['Dataset']]).T\n",
    "\n",
    "        df_ABD12 = pd.concat([df_ABD1, df_ABD2], axis=0)\n",
    "\n",
    "        df_plot = df_ABD12[df_ABD12[score_name]>0]\n",
    "\n",
    "        plt.figure(figsize=(10,7))\n",
    "        sns.set(style = 'whitegrid', font_scale=1.5)\n",
    "        g = sns.pointplot(x = 'ASD Subtype' , y = score_name, hue = 'Dataset', data = df_plot,  palette = \"gray\", plot_kws=dict(alpha=1))\n",
    "        plt.xticks([0,1,2],['ASD 1','ASD 2', 'ASD 3'], fontsize=40)\n",
    "        plt.xlabel('Subtype', fontsize = 40)\n",
    "        plt.ylabel(score_name, fontsize = 40)\n",
    "        plt.legend(fontsize=30)\n",
    "        # plt.ylim([0,8])\n",
    "        # plt.yticks([0,2,4,6])\n",
    "        plt.setp(g.collections, alpha = 1)\n",
    "        plt.setp(g.lines[5:8], alpha=.5)  \n",
    "        # sns.swarmplot(x = 'ASD Subtype' , y = 'ADOS Communication', data = df_plot, color = '.25')\n",
    "\n",
    "        is_ABD1 = df_plot['Dataset'] == 'Discovery'\n",
    "        is_ABD2 = df_plot['Dataset'] == 'Replication'\n",
    "        is_sub1 = df_plot['ASD Subtype'] == 1\n",
    "        is_sub2 = df_plot['ASD Subtype'] == 2\n",
    "        is_sub3 = df_plot['ASD Subtype'] == 3\n",
    "\n",
    "        chi_ob=[]\n",
    "        chi_expect=[]\n",
    "\n",
    "        for num in [is_sub1, is_sub2, is_sub3]:\n",
    "            print('p value : ',np.round(sc.stats.ttest_ind(df_plot[num & is_ABD1][score_name],df_plot[num & is_ABD2][score_name])[1], 4))\n",
    "            print('ABIDE 1 score : ',np.round(df_plot[num & is_ABD1][score_name].mean(),2),' +- ', np.round(df_plot[num & is_ABD1][score_name].std(),2))\n",
    "            print('ABIDE 2 score : ',np.round(df_plot[num & is_ABD2][score_name].mean(),2),' +- ', np.round(df_plot[num & is_ABD2][score_name].std(),2))\n",
    "            print(' ')\n",
    "            chi_expect.append(df_plot[num & is_ABD1][score_name].mean())\n",
    "            chi_ob.append(df_plot[num & is_ABD2][score_name].mean())\n",
    "\n",
    "        # Chi square test between ABD1 and ABD2\n",
    "        print(np.round(chi_ob,2))\n",
    "        print(np.round(chi_expect,2))\n",
    "        print('')\n",
    "        print('Chi Square')\n",
    "        print('static : ', np.round(sc.stats.chisquare(chi_ob, f_exp=chi_expect, axis=None, ddof = 0).statistic,3))\n",
    "        print('p value : ',np.round(sc.stats.chisquare(chi_ob, f_exp=chi_expect, axis=None, ddof = 0).pvalue,3))\n",
    "        print(' ')\n",
    "        \n",
    "    else:\n",
    "        print(f'@@ {score_name} @@')\n",
    "\n",
    "        df_ABD1 = DataFrame([ABD1_Score[score_name], ABD1_Score['ASD Subtype'], ABD1_Score['Dataset']]).T\n",
    "        df_plot = df_ABD1[df_ABD1[score_name]>0]\n",
    "        \n",
    "        is_ABD1 = df_plot['Dataset'] == 'Discovery'\n",
    "        is_sub1 = df_plot['ASD Subtype'] == 1\n",
    "        is_sub2 = df_plot['ASD Subtype'] == 2\n",
    "        is_sub3 = df_plot['ASD Subtype'] == 3\n",
    "        \n",
    "        for num in [is_sub1, is_sub2, is_sub3]:\n",
    "            print('ABIDE 1 score : ',np.round(df_plot[num & is_ABD1][score_name].mean(),2),' +- ', np.round(df_plot[num & is_ABD1][score_name].std(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttest\n",
    "def subtype_ranksum(a,b):\n",
    "    import statsmodels as sm\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "    \n",
    "    input_a = a # [X, Y, Z, X, X, Y, W]\n",
    "    input_b = b # [S, S, S, Y, Z, Z, R]\n",
    "\n",
    "    s_1 = []\n",
    "    p_1 = []\n",
    "\n",
    "    for col in range(input_a.shape[1]):\n",
    "        [s,p] = sc.stats.ranksums(input_a[:,col],input_b[:,col])\n",
    "        s_1.append(s)\n",
    "        p_1.append(p)\n",
    "    \n",
    "#     [s_1,p_1] = sc.stats.ttest_ind(input_a, input_b, axis=0, equal_var=False)\n",
    "    \n",
    "    s_1 = np.array(s_1)\n",
    "    p_1 = np.array(p_1)\n",
    "\n",
    "    # Calculate Effect size r\n",
    "    effect_r = s_1/np.sqrt(len(input_a)+len(input_b))\n",
    "\n",
    "    p_1_fdr_05 = sm.stats.multitest.multipletests(p_1,alpha=0.2,method='fdr_bh')\n",
    "    p_1_fdr_01 = sm.stats.multitest.multipletests(p_1,alpha=0.01,method='fdr_bh')\n",
    "    p_1_fdr_001 = sm.stats.multitest.multipletests(p_1,alpha=0.001,method='fdr_bh')\n",
    "\n",
    "    print('FDR uncorrected : ', np.where(p_1 <0.05)[0], np.where(p_1 <0.05)[0].shape )\n",
    "    print('')\n",
    "    print(np.where(p_1_fdr_05[0]==True),'\\n', np.where(p_1_fdr_05[0]==True)[0].shape)\n",
    "    print('FDR 0.05 : ', p_1_fdr_05[1][np.where(p_1_fdr_05[0]==True)[0]])\n",
    "    print('')\n",
    "#     print(np.where(p_1_fdr_01[0]==True),'\\n', np.where(p_1_fdr_01[0]==True)[0].shape)\n",
    "#     print('FDR 0.01 : ', p_1_fdr_01[1][np.where(p_1_fdr_01[0]==True)[0]])\n",
    "#     print('')\n",
    "#     print(np.where(p_1_fdr_001[0]==True),'\\n', np.where(p_1_fdr_001[0]==True)[0].shape)\n",
    "#     print('FDR 0.001 : ', p_1_fdr_001[1][np.where(p_1_fdr_001[0]==True)[0]])\n",
    "\n",
    "    sign_idx = np.where(p_1_fdr_05[0]==True)[0]\n",
    "    sign_idx_uncorr = np.where(p_1 <0.05)[0]\n",
    "    \n",
    "    ttest_tval = np.zeros(360)\n",
    "    input_idx = sign_idx \n",
    "    ttest_tval[input_idx] = effect_r[input_idx] \n",
    "       \n",
    "    return ttest_tval, sign_idx_uncorr\n",
    "\n",
    "# Prepare visualization\n",
    "\n",
    "def ROI_visualization(input_stat,stats = 'Ttest'):\n",
    "\n",
    "    import vtk\n",
    "    from vtk import vtkPolyDataNormals\n",
    "    from brainspace.mesh.mesh_io import read_surface\n",
    "    from brainspace.mesh.mesh_operations import combine_surfaces\n",
    "    from brainspace.utils.parcellation import reduce_by_labels\n",
    "    from brainspace.vtk_interface import wrap_vtk, serial_connect\n",
    "\n",
    "    template_path = join(atlas_path,\"MMP\")\n",
    "    template_L = \"L.very_inflated_MSMAll.10k_fs_LR.surf.gii\" # S900.L.midthickness_MSMAll.10k_fs_LR.surf.gii # L.very_inflated_MSMAll.10k_fs_LR.surf.gii\n",
    "    template_R = \"R.very_inflated_MSMAll.10k_fs_LR.surf.gii\" # S900.R.midthickness_MSMAll.10k_fs_LR.surf.gii # R.very_inflated_MSMAll.10k_fs_LR.surf.gii\n",
    "\n",
    "    surfs = [None] * 2\n",
    "    \n",
    "    surfs[0] = read_surface(join(template_path,template_L)) # Z:/hschoi/backup/hschoi/template/MMP/S900.L.midthickness_MSMAll.10k_fs_LR.surf.gii\n",
    "    nf = wrap_vtk(vtkPolyDataNormals, splitting=False, featureAngle=0.1)\n",
    "    surf_lh = serial_connect(surfs[0], nf)\n",
    "\n",
    "    surfs[1] = read_surface(join(template_path,template_R)) # Z:/hschoi/backup/hschoi/template/MMP/S900.R.midthickness_MSMAll.10k_fs_LR.surf.gii\n",
    "    nf = wrap_vtk(vtkPolyDataNormals, splitting=False, featureAngle=0.1)\n",
    "    surf_rh = serial_connect(surfs[1], nf)\n",
    "\n",
    "    # Visualization\n",
    "\n",
    "    from brainspace.datasets import load_group_fc, load_parcellation, load_conte69\n",
    "    from brainspace.gradient import GradientMaps\n",
    "    from brainspace.plotting import plot_hemispheres\n",
    "    from brainspace.utils.parcellation import map_to_labels\n",
    "\n",
    "    atlas = np.load(join(template_path,\"MMP.10k_fs_LR.npy\"))\n",
    "    labeling = atlas \n",
    "    conn_matrix = input_stat \n",
    "    mask = labeling != 0\n",
    "    grad = map_to_labels(conn_matrix, labeling, mask=mask, fill=np.nan) # fill = np.nan fill = 0\n",
    "\n",
    "    if stats == 'ANOVA':\n",
    "        plot_hemispheres(surf_lh, surf_rh, array_name=grad, size=(1300, 300),\n",
    "                         color_bar=True, cmap='Reds_r', zoom=1.25, nan_color=(0,0,0,1) ,color_range = (0,0.5)   ) \n",
    "                                                                                                                       \n",
    "    elif stats == 'Ttest':\n",
    "        plot_hemispheres(surf_lh, surf_rh, array_name=grad, size=(1300, 300),\n",
    "                         color_bar=True, cmap='seismic', zoom=1.25, nan_color=(0,0,0,1) ,color_range = (-1,1) , view = 'dorsal'  )  # ventral dorsal\n",
    "                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest\n",
    "X = ASD_DMN_pc_sub1\n",
    "Y = ASD_DMN_pc_sub2 \n",
    "Z = ASD_DMN_pc_sub3\n",
    "W = TD_DMN_pc_sub1\n",
    "R = TD_DMN_pc_sub2 \n",
    "V = TD_DMN_pc_sub3\n",
    "\n",
    "S = np.concatenate((W,R))\n",
    "U = np.concatenate((X,Y,Z))\n",
    "\n",
    "print('T-test')\n",
    "print('ASD sub1')\n",
    "effect_r_ASD1_TD, ASD1_TD_idx = subtype_ranksum(X,S)\n",
    "print('ASD sub2')\n",
    "effect_r_ASD2_TD, ASD2_TD_idx = subtype_ranksum(Y,S)\n",
    "print('ASD sub3')\n",
    "effect_r_ASD3_TD, ASD3_TD_idx = subtype_ranksum(Z,S)\n",
    "print('ASD sub12')\n",
    "effect_r_ASD12, ASD12_idx = subtype_ranksum(X,Y)\n",
    "print('ASD sub13')\n",
    "effect_r_ASD13, ASD13_idx = subtype_ranksum(X,Z)\n",
    "print('ASD sub23')\n",
    "effect_r_ASD23, ASD23_idx = subtype_ranksum(Y,Z)\n",
    "print('TD sub12')\n",
    "effect_r_TD12, TD12_idx = subtype_ranksum(W,R)\n",
    "\n",
    "# print('')\n",
    "# print('ANOVA')\n",
    "# ANOVA_eta = subtype_kruskal(X,Y,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI_visualization(ANOVA_eta, stats = 'ANOVA')\n",
    "ROI_visualization(effect_r_ASD1_TD, stats = 'Ttest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make file for Neurosynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_for_Neurosynth(input_stats, subtype_name = 'ASD1'):\n",
    "\n",
    "    atlas = np.load(join(template_path,\"MMP.10k_fs_LR.npy\"))\n",
    "\n",
    "    atlas_L = atlas[:10242]\n",
    "    atlas_R = atlas[10242:]\n",
    "\n",
    "    # atlas.max()\n",
    "\n",
    "    atlas_sig=np.zeros(len(atlas))\n",
    "    for i in input_stats:                       # ASD12_idx ASD13_idx ASD23_idx ASD1_TD12_idx ASD2_TD12_idx ASD3_TD12_idx\n",
    "        print(i+1, ' ', end='', flush=True)\n",
    "\n",
    "        atlas_sig[np.where(atlas==i+1)[0]] = cohens_d[i]\n",
    "\n",
    "    atlas_sig_L = atlas_sig[:10242]\n",
    "    atlas_sig_R = atlas_sig[10242:]\n",
    "\n",
    "    np.save(join(path_gii_data,f'L.MMP.10k.ef_r_{subtype_name}_TD_ABD2.npy'),atlas_sig_L) # atlas\n",
    "    np.save(join(path_gii_data,f'R.MMP.10k.ef_r_{subtype_name}_TD_ABD2.npy'),atlas_sig_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_for_Neurosynth(ASD1_ranksum_idx, subtype_name = 'ASD1')\n",
    "file_for_Neurosynth(ASD2_ranksum_idx, subtype_name = 'ASD2')\n",
    "file_for_Neurosynth(ASD3_ranksum_idx, subtype_name = 'ASD3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gudtls17_py36",
   "language": "python",
   "name": "gudtls17_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
